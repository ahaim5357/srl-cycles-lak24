{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66e57570",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643b6fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyError(Exception):\n",
    "    pass\n",
    "\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "from io import StringIO\n",
    "import time\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fe6e60",
   "metadata": {},
   "source": [
    "## Step 1: Preprocess log data and establish reference time stamps for think-aloud transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc2f4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def process_timestamp_zoom(s):\n",
    "    x = time.strptime(s, '%H:%M:%S.%f')\n",
    "    ans = 3600* x.tm_hour + 60* x.tm_min + x.tm_sec + float('.'+s.split('.')[-1])\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6118fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User ID Crosswalk\n",
    "crosswalk = {\n",
    "    'Stu_9a771c37547c1ce5bb0e3ccd2ffa890a': 'user_1',\n",
    "    'Stu_ef57d8fdab9d03a879b85fabdb5ce8c8': 'user_2',\n",
    "    'Stu_12784370c142151213cedf0d527455f9': 'user_2',\n",
    "    'Stu_b0e687db63e81cfbdd64f22804c5967d': 'user_3',\n",
    "    'Stu_651e714c97d469adf89a47bb73e81fdb': 'user_4',\n",
    "    'Stu_954e7ff89b99dedcd9aa613308a3b2ab': 'user_5',\n",
    "    'Stu_1279946571c2fb21a88d1f22340d6a21': 'user_6',\n",
    "    'Stu_a02379c766c89e55794be249dee8101a': 'user_7',\n",
    "    'Stu_eeea2cac9ae40df584566c798a0384e7': 'user_8',\n",
    "    'Stu_187d5dc77c2259af31b59badf210161b': 'user_9',\n",
    "    'Stu_6ae9d35793ea37302b302dee4b4d0c19': 'user_10'\n",
    "}\n",
    "\n",
    "df = pd.read_csv('logs/ds5371_tx_All_Data_7671_2023_0520_042939.txt', sep='\\t')\n",
    "\n",
    "df.sort_values(by = ['Anon Student Id', 'Time'])\n",
    "\n",
    "df['Time'] = df.Time.map(lambda s: datetime.strptime(s, '%Y-%m-%d %H:%M:%S'))\n",
    "df = df.sort_values(by = 'Time').copy()\n",
    "\n",
    "df = df[df['Anon Student Id'].isin(crosswalk.keys())].copy()\n",
    "\n",
    "df['Participant'] = df['Anon Student Id'].map(crosswalk)\n",
    "\n",
    "df = df.sort_values(by = ['Participant', 'Time'])\n",
    "\n",
    "df2 = df[['Transaction Id', 'Participant', 'Time', 'Step Name', 'Selection', 'Action', 'Input', 'Outcome']]\n",
    "\n",
    "df2.to_csv('transaction-ref.csv', index=False) # For reference\n",
    "\n",
    "# Hand-coded time references for synchronizing \n",
    "# think-aloud and tutor timestamps, with some users having \n",
    "# multiple recordings.\n",
    "\n",
    "codes = \"\"\"Transaction Id\tTransaction Id Time\tFile\n",
    "f9a193cdfc7b85d193304b4476068bfd\t\"00:00:37.94\"\tuser-1\n",
    "47a9063f57366fb5c44b753de6fd00d4\t\"00:04:21.91\"\tuser-2\n",
    "7f7b0014d9a8e2bf8b8ffe896022053d\t\"00:00:55.68\"\tuser-2-extra\n",
    "083b0beee70cb2a8a5848747acd19d99\t\"00:02:20.91\"\tuser-3\n",
    "435ad5758959790983c52583095645d2\t\"00:02:18.36\"\tuser-4\n",
    "7dc2f7c64eeb494f8d583f01f8b227c9\t\"00:01:16.01\"\tuser-4-extra\n",
    "954b6639595169b8b3960e84e05d2549\t\"00:00:58.81\"\tuser-5\n",
    "c4da6cb61d25ac4b769cc471f0e278f4\t\"00:05:15.96\"\tuser-6\n",
    "533c935c169ff4ef093bca2be39beb73\t\"00:27:41.08\"\tuser-6#2\n",
    "1dc468a3a003f8b729dc07adc1c7c096\t\"00:01:17.01\"\tuser-7\n",
    "356e38369fd586fac5460214ce19f23f\t\"00:00:39.28\"\tuser-8\n",
    "8c384c7cb6fc1c82c16e2c24b0dd0c46\t\"00:28:52.02\"\tuser-8#2\n",
    "16afe7343c97e91216c39ddac89167e0\t\"00:01:55.33\"\tuser9\n",
    "eae9ffaa67c98cf5e954f36ad1cc80c4\t\"00:18:26.60\"\tuser9#2\n",
    "31c708ea230a79c3257ff4045fff447d\t\"00:03:52.23\"\tuser10\n",
    "8d2e1a475bef2c6563311ee6053ffe1a\t\"00:23:08.81\"\tuser10#2\"\"\"\n",
    "\n",
    "df_join = pd.read_csv(StringIO(codes), sep='\\t')\n",
    "\n",
    "# Join reference timestamps for think-aloud timestamps\n",
    "df = df.merge(df_join, how = 'left', on = 'Transaction Id')\n",
    "\n",
    "df['has_reference_timestamp'] = df['Transaction Id Time'].map(pd.isna)\n",
    "\n",
    "df['Transaction Id Time Num'] =\\\n",
    "    df['Transaction Id Time'].map(lambda x: np.nan if pd.isna(x) else process_timestamp_zoom(x))\n",
    "\n",
    "df['Transaction Id Time Num'] = df['Transaction Id Time Num'].ffill() # Sorted by anon id, time!\n",
    "\n",
    "# Tutortime to reset at recording reset\n",
    "df['TimeDiff'] = np.where(df['has_reference_timestamp'], (df.Time - df.Time.shift()).map(lambda s: s.total_seconds()), np.nan)\n",
    "v = df['TimeDiff']\n",
    "cumsum = v.cumsum().fillna(method='pad')\n",
    "reset = -cumsum[v.isnull()].diff().fillna(cumsum)\n",
    "result = v.where(v.notnull(), reset).cumsum()\n",
    "\n",
    "# Time difference to reference timestamp is used to synchronize with think-aloud transcripts\n",
    "df['TimeDiffCumsum'] = result \n",
    "\n",
    "# Preprocess/fill remaining relative recording times\n",
    "df['RecordingTime'] = df['TimeDiffCumsum'] + df['Transaction Id Time Num']\n",
    "\n",
    "# Fill first time point\n",
    "df['RecordingTime'] =\\\n",
    "    df[['RecordingTime', 'Transaction Id Time Num']]\\\n",
    "        .agg(lambda row: row['Transaction Id Time Num'] if pd.isna(row['RecordingTime']) else row['RecordingTime'], axis = 1)\n",
    "\n",
    "df[['Transaction Id', 'Participant', 'File', 'Transaction Id Time', 'has_reference_timestamp', \n",
    "    'TimeDiff', 'TimeDiffCumsum', 'RecordingTime']].to_csv('inspect.csv', index=False)\n",
    "\n",
    "# Remove tutor-performed actions\n",
    "df = df[df['Student Response Subtype'] != 'tutor-performed'].copy()\n",
    "df = df[df['Input'] != '-1'].copy()\n",
    "\n",
    "# Preprocessed object for later reference\n",
    "df_tutor = df.copy().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd53b7a",
   "metadata": {},
   "source": [
    "## Step 2: Read in transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8de6804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-person sessions\n",
    "files = [\n",
    "   'transcripts/user_1_thinkaloud_s23_condition_1.vtt',\n",
    "    'transcripts/user_2_thinkaloud_s23_condition_2.vtt',\n",
    "    'transcripts/user_2_thinkaloud_s23_condition_2_extra.vtt',\n",
    "    'transcripts/user_3_thinkaloud_s23_condition_3.vtt',\n",
    "    'transcripts/user_4_thinkaloud_s23_condition_4.vtt',\n",
    "    'transcripts/user_4_thinkaloud_s23_condition_4_extra.vtt',\n",
    "    'transcripts/user_5_thinkaloud_s23_condition_5.vtt',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85f30d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoom sessions\n",
    "zoomfiles = [f'zoomtranscripts/user{i}zoom.vtt' for i in range(6, 10+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6266c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conductor names whose utterances in Zoom should be ignored (redacted)\n",
    "NAMES_TO_SKIP = [\n",
    "    'Conrad Borchers'\n",
    "]\n",
    "\n",
    "def process_timestamp(s):\n",
    "    x = time.strptime(s, '%M:%S.%f')\n",
    "    ans = 3600* x.tm_hour + 60* x.tm_min + x.tm_sec + float(s[-4:])\n",
    "    return ans\n",
    "\n",
    "def process_zoomfile(f):\n",
    "    with open(f, 'r') as file:\n",
    "        lines = [line.rstrip() for line in file]\n",
    "\n",
    "    # Remove 2 lines preamble\n",
    "    lines = lines[2:]\n",
    "\n",
    "    # Sequences are always Number, Time, Name: Speech, Blank\n",
    "    times, speakers, contents = [], [], []\n",
    "    for i, line in enumerate(lines):\n",
    "        if i%4 in [0, 3]:\n",
    "            continue\n",
    "        if i%4 == 1:\n",
    "            times.append(line)\n",
    "        else:\n",
    "            elements = line.split(':', 1)\n",
    "            if len(elements) == 1:\n",
    "                speakers.append('UNKNOWN')\n",
    "                contents.append(elements[0])\n",
    "            else:\n",
    "                speakers.append(elements[0])\n",
    "                contents.append(elements[1])\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'file': [f for _ in range(len(times))],\n",
    "        'time': times,\n",
    "        'speaker': speakers,#['Speaker ' + str(hash(s)) for s in speakers], # if user is not de-identified yet\n",
    "        'content': contents\n",
    "    })\n",
    "\n",
    "    # Remove conductor and unknown speakers from analysis\n",
    "    df = df[~df['speaker'].isin(NAMES_TO_SKIP + ['UNKNOWN'])].copy()\n",
    "    \n",
    "    # Standardize format\n",
    "    df = df.rename(columns={'speaker': 'user'})\n",
    "    df['user'] = df.user.map(lambda s: s.replace('cmu-', '').replace('-', '_'))\n",
    "    df = df[['user', 'time', 'content']]\n",
    "\n",
    "    df['start'] = df.time.map(lambda s: s.split(' --> ')[0])\n",
    "    df['end'] = df.time.map(lambda s: s.split(' --> ')[1])\n",
    "   \n",
    "    df['start'] = df['start'].map(process_timestamp_zoom)\n",
    "    df['end'] = df['end'].map(process_timestamp_zoom)\n",
    "    \n",
    "    df['center'] = df['start'] + (df['end'] - df['start'])/2\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9476e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(f):\n",
    "    with open(f, 'r') as file:\n",
    "        lines = [line.rstrip() for line in file]\n",
    "\n",
    "    # Remove 2 lines preamble\n",
    "    lines = lines[2:]\n",
    "\n",
    "    # Sequences are always Number, Time, Name: Speech, Blank\n",
    "    times, speakers, contents = [], [], []\n",
    "    for i, line in enumerate(lines):\n",
    "        if i%3 == 2:\n",
    "            continue\n",
    "        if i%3 == 0:\n",
    "            times.append(line)\n",
    "        else:\n",
    "            contents.append(line)\n",
    "    \n",
    "    suff = '_extra' if '_extra' in f else ''  \n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'user': [f.split('/')[-1].split('_thinkaloud')[0]+suff for _ in range(len(times))],\n",
    "        'time': times,\n",
    "        'content': contents\n",
    "    })\n",
    "    \n",
    "    df['start'] = df.time.map(lambda s: s.split(' --> ')[0])\n",
    "    df['end'] = df.time.map(lambda s: s.split(' --> ')[1])\n",
    "   \n",
    "    df['start'] = df['start'].map(process_timestamp)\n",
    "    df['end'] = df['end'].map(process_timestamp)\n",
    "    \n",
    "    df['center'] = df['start'] + (df['end'] - df['start'])/2\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a128f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export\n",
    "df_inperson = pd.concat([process_file(file) for file in files])\n",
    "df_zoom = pd.concat([process_zoomfile(file) for file in zoomfiles])\n",
    "df = pd.concat([df_inperson, df_zoom])\n",
    "df = df.sort_values(by = ['user', 'start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c27ce13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transcript = df.copy().reset_index()\n",
    "df_transcript_export = df_transcript.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572c5800",
   "metadata": {},
   "source": [
    "## Step 3: Postprocess and join tutor log data context to transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf7ad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Add real time based on log synchronization\n",
    "to_join = pd.read_csv('logs/ds5371_tx_All_Data_7671_2023_0520_042939.txt', sep='\\t')\n",
    "time_ref = df_join.merge(to_join[['Transaction Id', 'Time']], \n",
    "                         how='left', on='Transaction Id')[['File', 'Transaction Id Time', 'Time']]\n",
    "time_ref['File'] = time_ref['File'].map(lambda s: s.replace('-', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfdc6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transcript_export2 = df_transcript_export.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e72b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "def add_seconds_to_timestamp(timestamp, seconds):\n",
    "    # Convert the timestamp to a datetime object\n",
    "    dt = datetime.strptime(timestamp, \"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    # Create a timedelta object with the specified number of seconds\n",
    "    delta = timedelta(seconds=seconds)\n",
    "    \n",
    "    # Add or subtract the timedelta from the datetime object\n",
    "    new_dt = dt + delta\n",
    "    \n",
    "    # Convert the new datetime object back to a string\n",
    "    new_timestamp = new_dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    return new_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cf12ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code itterates through transcriptions to synchronize \n",
    "# the relative time of think-aloud transcripts with the absolute\n",
    "# time of tutor log data, by looking up values in time_ref.\n",
    "# Conditional logic deals with multiple recording files per user.\n",
    "\n",
    "df_transcript_export2['start_real'] = ''\n",
    "df_transcript_export2['end_real'] = ''\n",
    "for index, row in df_transcript_export2.iterrows():\n",
    "    has_cut_jump = False\n",
    "    user = row['user']\n",
    "    if not 'extra' in user:\n",
    "        user_ref = user.replace('_', '')\n",
    "        ref_slice = time_ref[time_ref['File'] == user_ref].copy()\n",
    "        ref_time = ref_slice['Transaction Id Time'].values[0]\n",
    "        ref_real = ref_slice['Time'].values[0]\n",
    "        if user_ref+'#2' in time_ref['File'].values:\n",
    "            ref_slice = time_ref[time_ref['File'] == user_ref+'#2'].copy()\n",
    "            ref_time_second = ref_slice['Transaction Id Time'].values[0]\n",
    "            ref_real_second = ref_slice['Time'].values[0]\n",
    "            has_cut_jump = True\n",
    "    else:\n",
    "        user_ref = user.replace('_', '')\n",
    "        ref_slice = time_ref[time_ref['File'] == user_ref].copy()\n",
    "        ref_time = ref_slice['Transaction Id Time'].values[0]\n",
    "        ref_real = ref_slice['Time'].values[0]\n",
    "    st = row['start']\n",
    "    en = row['end']\n",
    "    if not has_cut_jump:\n",
    "        st_diff = st - process_timestamp_zoom(ref_time)\n",
    "        en_diff = en - process_timestamp_zoom(ref_time)\n",
    "        df_transcript_export2.loc[index, 'start_real'] =\\\n",
    "            add_seconds_to_timestamp(ref_real, st_diff)\n",
    "        df_transcript_export2.loc[index, 'end_real'] =\\\n",
    "            add_seconds_to_timestamp(ref_real, en_diff)\n",
    "    else:\n",
    "        if st > process_timestamp_zoom(ref_time_second):\n",
    "            st_diff = st - process_timestamp_zoom(ref_time_second)\n",
    "            df_transcript_export2.loc[index, 'start_real'] =\\\n",
    "                add_seconds_to_timestamp(ref_real_second, st_diff)\n",
    "        else:\n",
    "            st_diff = st - process_timestamp_zoom(ref_time)\n",
    "            df_transcript_export2.loc[index, 'start_real'] =\\\n",
    "                add_seconds_to_timestamp(ref_real, st_diff)\n",
    "        if en > process_timestamp_zoom(ref_time_second):\n",
    "            en_diff = en - process_timestamp_zoom(ref_time_second)\n",
    "            df_transcript_export2.loc[index, 'end_real'] =\\\n",
    "                add_seconds_to_timestamp(ref_real_second, en_diff)\n",
    "        else:\n",
    "            en_diff = en - process_timestamp_zoom(ref_time)\n",
    "            df_transcript_export2.loc[index, 'end_real'] =\\\n",
    "                add_seconds_to_timestamp(ref_real, en_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8b7dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transcript_export2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9f2656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code adds tutor context to transcripts based\n",
    "# on the now synchonized timestamps and the closest available\n",
    "# tutor transactions for each utterance.\n",
    "\n",
    "df_transcript_export2['selection_before'] = ''\n",
    "df_transcript_export2['action_before'] = ''\n",
    "df_transcript_export2['input_before'] = ''\n",
    "df_transcript_export2['feedback_before'] = ''\n",
    "for index, row in df_transcript_export2.iterrows():\n",
    "    st = datetime.strptime(row['start_real'], '%Y-%m-%d %H:%M:%S')\n",
    "    st_delta = st - df_tutor['Time']\n",
    "    st_delta_pos = st_delta[st_delta >= np.timedelta64(0)]\n",
    "    if not len(st_delta_pos) == 0:\n",
    "        i_before = np.argmin(st_delta_pos)\n",
    "    else:\n",
    "        i_before = np.argmax(st_delta)\n",
    "    selection_before = df_tutor['Selection'].values[i_before]\n",
    "    action_before = df_tutor['Action'].values[i_before]\n",
    "    input_before = df_tutor.Input.values[i_before]\n",
    "    feedback_before = df_tutor['Feedback Text'].values[i_before]\n",
    "    transaction_id_before = df_tutor['Transaction Id'].values[i_before]\n",
    "    df_transcript_export2.loc[index, 'selection_before'] = selection_before\n",
    "    df_transcript_export2.loc[index, 'action_before'] = action_before\n",
    "    df_transcript_export2.loc[index, 'input_before'] = input_before\n",
    "    df_transcript_export2.loc[index, 'feedback_before'] = feedback_before\n",
    "    df_transcript_export2.loc[index, 'transaction_id_before'] = transaction_id_before\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffab627e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join platform and problem ID\n",
    "df_tutor['problem_id'] = df_tutor['Problem Name'].map(lambda s: int(re.sub('[a-zA-Z_-]', '', s)))\n",
    "df_tutor['platform'] = df_tutor['Problem Name'].map(lambda s: 'Stoich' if 'Stoich' in s else 'ORCCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833d4084",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transcript_export3 = df_transcript_export2.merge(\n",
    "    df_tutor[['Transaction Id', 'platform', 'problem_id']],\n",
    "    how = 'left', left_on = 'trbransaction_id_before', right_on = 'Transaction Id'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3685d80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export for hand-coding of problem ID and platform \n",
    "df_transcript_export3\\\n",
    "    .sort_values(by = ['user', 'start'])\\\n",
    "    .to_csv('transcripts-with-tutor-context.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c31b37",
   "metadata": {},
   "source": [
    "## Use the following R code to summarize utterances by in-tutor attempts for hand-coding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6d3773",
   "metadata": {},
   "source": [
    "```\n",
    "df_utterance = read.csv(\"transcripts-with-tutor-context.csv\")\n",
    "\n",
    "df_utterance = \n",
    "  df_utterance %>% \n",
    "  fill(problem_id) %>% \n",
    "  mutate(\n",
    "    rowNumber = row_number(),\n",
    "    instance = ifelse(selection_before == lag(selection_before),NA,rowNumber))\n",
    "    \n",
    "# Forward fill the missing values in df_utterance$instance\n",
    "df_utterance$instance <- zoo::na.locf(df_utterance$instance, na.rm = FALSE)\n",
    "\n",
    "df_utterance_combined = \n",
    "  df_utterance %>% \n",
    "  group_by(user,platform,problem_id,selection_before,input_before,feedback_before,instance) %>% \n",
    "  summarise(utterance_combined = paste(unique(content), collapse = '/'), \n",
    "             feedback_combined = paste(unique(feedback_before), collapse='##'),\n",
    "           input_combined = paste(unique(input_before), collapse='##') ) %>% \n",
    "  arrange(user,platform,problem_id,instance)\n",
    "\n",
    "write.csv(df_utterance_combined, \"utterance-for-coding.csv\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
